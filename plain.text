This screenshot gives us a clean, modern portfolio layout with:

A top navigation: Name, About, Projects, Contact

A hero section: "AI-Powered Portfolio" headline with subtitle

Project cards: Each card shows project name, description, tech tags

Chatbot modal: Bottom-right, AI assistant for questions, compact bubble design




AI-Powered Portfolio Setup Prompt (Next.js 2025)
Project Repository
https://github.com/Gmpho/AI-portfolio.git

Big Picture

Create a Next.js App Router + TypeScript AI-powered portfolio with:

Self-learning career coach chatbot

Project showcase

AI services: OpenAI, Ollama (local/offline LLM), Notion API, Pinecone

ShadCN UI components

LangChain Agent Executor

MCC/MCP support (Smithery.ai)

Observability: Sentry, synthetic checks

Deployment: Cloudflare Pages/Workers + GitHub Actions

DevSecOps: Secrets handling, automatic fallbacks, circuit breakers, feature flags

1. Project Initialization
# Clone repo
git clone https://github.com/Gmpho/AI-portfolio.git
cd AI-portfolio

# Initialize Next.js app with App Router & TypeScript
npx create-next-app@latest . --ts --app

# Install core SDKs
npm install openai @notionhq/client @pinecone-database/pinecone pdfjs-dist ollama

# Tailwind + ShadCN UI
npm install -D tailwindcss postcss autoprefixer
npx tailwindcss init -p
npx shadcn-ui@latest init

# Additional UI libraries
npm install lucide-react clsx @radix-ui/react-popover

# Dev tooling
npm install -D eslint prettier @typescript-eslint/eslint-plugin @typescript-eslint/parser
npm install -D wrangler # Cloudflare Pages deploy helper

2. Project Structure (Next.js + TypeScript)
ai-portfolio/
├── app/
│   ├── api/
│   │   ├── openai/route.ts
│   │   ├── pinecone/route.ts
│   │   ├── notion/route.ts
│   │   └── ollama/route.ts
│   ├── layout.tsx
│   ├── page.tsx
│   └── components/
│       ├── ChatBot/
│       ├── ProjectCard/
│       ├── ThemeToggle/
│       └── ResumeUpload/
├── src/
│   ├── services/
│   │   ├── openaiService.ts
│   │   ├── notionService.ts
│   │   ├── pineconeService.ts
│   │   └── ollamaService.ts
│   ├── hooks/
│   │   ├── useChat.ts
│   │   └── useAI.ts
│   ├── types/
│   ├── utils/
│   ├── config/
│   └── data/
├── public/
├── .github/workflows/deploy.yml
├── tailwind.config.js
├── postcss.config.js
├── tsconfig.json
├── next.config.js
├── .env.example
└── README.md

3. Core Configuration

Tailwind CSS

// tailwind.config.js
export default {
  content: ["./app/**/*.{ts,tsx}", "./components/**/*.{ts,tsx}"],
  theme: { extend: {} },
  plugins: [],
};


Environment Variables (.env)

NEXT_PUBLIC_OPENAI_API_KEY=...
NEXT_PUBLIC_NOTION_API_KEY=...
NEXT_PUBLIC_NOTION_DATABASE_ID=...
NEXT_PUBLIC_PINECONE_API_KEY=...
NEXT_PUBLIC_PINECONE_ENVIRONMENT=...
NEXT_PUBLIC_PINECONE_INDEX=...

4. AI Services Integration

OpenAI: Chat completions & embeddings

Ollama: Local/offline LLM fallback

Pinecone: Vector database for project/context storage

Notion: CMS for project content

LangChain Agent Executor: Automate multi-step tasks

Example: Ollama Service (src/services/ollamaService.ts)

import OpenAI from "openai";

const ollama = new OpenAI({
  baseURL: "http://localhost:11434/v1",
  apiKey: "ollama",
});

export const getCompletion = async (messages: any[]) => {
  return await ollama.chat.completions.create({
    model: "llama2",
    messages,
  });
};

5. Chatbot + Self-Learning

Tracks conversation history

Extracts skills from user messages

Updates user profile & career recommendations

Integrates with Pinecone + Notion for knowledge retrieval

Self-healing with circuit-breakers & API fallback to Ollama

6. DevSecOps & Observability

Sentry integration for monitoring:

import * as Sentry from "@sentry/nextjs";
Sentry.init({ dsn: process.env.SENTRY_DSN });


Secrets stored in GitHub/Cloudflare

Feature flags for toggling AI services

Circuit breakers for API failures

Compliance references: OWASP, SOC2, GDPR

7. CI/CD (GitHub Actions + Cloudflare)
# .github/workflows/deploy.yml
name: Deploy

on: [push]

jobs:
  deploy:
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v4
      - uses: actions/setup-node@v4
        with: node-version: 20
      - run: npm ci
      - run: npm run build
        env:
          NEXT_PUBLIC_OPENAI_API_KEY: ${{ secrets.NEXT_PUBLIC_OPENAI_API_KEY }}
          # ... other secrets
      - uses: cloudflare/wrangler-action@v2
        with:
          apiToken: ${{ secrets.CLOUDFLARE_API_TOKEN }}
          command: "publish"

8. Recommended AI-Powered Tasks

Generate initial folder structure + config files

Implement TypeScript interfaces for projects, chat, AI

Build ShadCN UI components (ChatBot, ProjectCard)

Integrate AI services with error boundaries

Implement LangChain agent executor for advanced workflows

Enable self-learning & knowledge extraction

Deploy & monitor via GitHub Actions + Cloudflare Pages

9. Success Criteria

Next.js app builds without errors

Chatbot responds correctly (fallback to Ollama if offline)

Projects displayed in responsive ShadCN grid

Theme system works persistently

CI/CD deploys seamlessly

Observability & DevSecOps protections active
We can use this as a visual blueprint for our Next.js + ShadCN UI implementation.

Here’s what I suggest as the next step:

Convert this layout to a Next.js App Router page (app/page.tsx).

Build reusable components: Navbar, HeroSection, ProjectCard, ChatBotModal.

Add Tailwind + ShadCN styling to match spacing, shadows, and rounded edges.

Integrate AI chatbot logic with OpenAI/Ollama services.

Optional: Animate the chatbot bubble and project card hover interactions.
